{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity Grad-CAM - add a random node at a random visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The current working directory needs to be in explainable_TGCNN\n",
    "print(os.getcwd())\n",
    "os.chdir('..\\\\')\n",
    "print(os.getcwd())\n",
    "\n",
    "import pandas as pd\n",
    "from src import whole_model_demographics_gradcam, graph_plot, gc, utils, create_fake_patients\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_TGCNN_layer = True\n",
    "demo = True\n",
    "\n",
    "include_drugs = True\n",
    "max_timesteps=100\n",
    "\n",
    "stride = 1\n",
    "filter_size = 4\n",
    "\n",
    "run_name='hip_1999_to_one_year_advance_model'\n",
    "years_in_advance = \"5\"\n",
    "\n",
    "if include_drugs:\n",
    "    max_event_codes = 518\n",
    "else:\n",
    "    max_event_codes = 512\n",
    "hip_or_knee = 'hip'\n",
    "\n",
    "# fake mapping dataframe for the ReadCodes and the corresponding descriptions\n",
    "read_code_map_df = pd.read_csv('fake_read_code_descriptions.csv')\n",
    "\n",
    "model = whole_model_demographics_gradcam.TGCNN_Model(num_filters=16, num_nodes=max_event_codes, num_time_steps=max_timesteps, \n",
    "                            filter_size=filter_size, variable_gamma=True, \n",
    "                            exponential_scaling=True, dropout_rate=0.7, lstm_units=64,\n",
    "                            fcl1_units=128, LSTM_ablation=False, stride=stride, activation_type='LeakyReLU', \n",
    "                            no_timestamp=False, second_TGCNN_layer=second_TGCNN_layer, num_labels=1)\n",
    "model.load_weights('hip_1999_to_one_year_advance_model1_CNN_layer')\n",
    "\n",
    "num_pats = 5\n",
    "cv_patients = create_fake_patients.create_fake_patient_df(num_pats, 99, max_event_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each patient, run the original graph (once) then loop through the modified graphs with psuedo nodes\n",
    "relu = False\n",
    "\n",
    "num_random_node = 10\n",
    "\n",
    "sensitivity_list = []\n",
    "for pat in range(num_pats):\n",
    "    \n",
    "    input_3d, input_4d, demo_tensor, outcome, outcome_bin = utils.return_pat_from_df(cv_patients, max_event_codes, hip_or_knee, pat, max_timesteps)\n",
    "    dense_tensor = tf.sparse.to_dense(input_3d)\n",
    "    dense_tensor= tf.transpose(dense_tensor, perm=[2, 1, 0])\n",
    "    dense_tensor = np.flip(dense_tensor, axis=0)\n",
    "    logits = model(input_4d, demo_tensor, training=False)\n",
    "\n",
    "    grads = model.dy_du_branch1\n",
    "\n",
    "    # Get the entire patient's history in a DataFrame\n",
    "    edges_df = graph_plot.create_edges_df_gc(dense_tensor)\n",
    "\n",
    "    # Get the node positions for the graph\n",
    "    pos_df = graph_plot.create_position_df_gc(edges_df)\n",
    "    pos_list = graph_plot.generate_pos_sequence(pos_df['max_codes_per_visit'].max())\n",
    "\n",
    "    pos_df = graph_plot.map_y_coord_to_node(pos_df, pos_list)\n",
    "\n",
    "    l_map = gc.calc_local_map(model, grads, only_pos=relu, filt_num=None)\n",
    "\n",
    "    timestep_ave_grad_df = gc.calc_timestep_weights(stride, filter_size, l_map, max_timesteps)\n",
    "\n",
    "    read_code_pos_df = gc.map_read_code_labels(pos_df, read_code_map_df, timestep_ave_grad_df)\n",
    "\n",
    "    v_mod_list, v_orig_list = [], []\n",
    "\n",
    "    for i in range(num_random_node):\n",
    "        # Generate individual data for the model\n",
    "        input_3d, input_4d, demo_tensor, outcome, outcome_bin, visit_num = utils.return_pat_from_df(cv_patients, max_event_codes, hip_or_knee, pat, max_timesteps, add_p_node=True)\n",
    "        dense_tensor = tf.sparse.to_dense(input_3d)\n",
    "        dense_tensor= tf.transpose(dense_tensor, perm=[2, 1, 0])\n",
    "        dense_tensor_p = np.flip(dense_tensor, axis=0)\n",
    "        logits = model(input_4d, demo_tensor, training=False)\n",
    "\n",
    "        grads = model.dy_du_branch1\n",
    "\n",
    "        # Get the entire patient's history in a DataFrame\n",
    "        p_edges_df = graph_plot.create_edges_df_gc(dense_tensor_p)\n",
    "\n",
    "        # Get the node positions for the graph\n",
    "        p_pos_df = graph_plot.create_position_df_gc(p_edges_df)\n",
    "        p_pos_list = graph_plot.generate_pos_sequence(p_pos_df['max_codes_per_visit'].max())\n",
    "\n",
    "        p_pos_df = graph_plot.map_y_coord_to_node(p_pos_df, p_pos_list)\n",
    "\n",
    "        p_l_map = gc.calc_local_map(model, grads, only_pos=relu, filt_num=None)\n",
    "\n",
    "        p_timestep_ave_grad_df = gc.calc_timestep_weights(stride, filter_size, p_l_map, max_timesteps)\n",
    "\n",
    "        p_read_code_pos_df = gc.map_read_code_labels(p_pos_df, read_code_map_df, p_timestep_ave_grad_df)\n",
    "\n",
    "        # get the difference in the percentage influence on the timestep with and without the psuedo node\n",
    "        mod_visit_infl = p_read_code_pos_df[p_read_code_pos_df['x']==visit_num]['perc_timestep_infl']\n",
    "        v_mod = mod_visit_infl.iloc[0]\n",
    "        \n",
    "        orig_visit_infl = read_code_pos_df[read_code_pos_df['x']==visit_num]['perc_timestep_infl']\n",
    "        v_orig = orig_visit_infl.iloc[0]\n",
    "        v_mod_list.append(v_mod)\n",
    "        v_orig_list.append(v_orig)\n",
    "\n",
    "\n",
    "\n",
    "    l1_norm = np.sum(np.abs(np.array(v_mod_list) - np.array(v_orig_list)))\n",
    "    ave_l1_norm = l1_norm / num_random_node\n",
    "    sensitivity_list.append(ave_l1_norm)\n",
    "    if (pat % 10) == 0 and (pat !=0):\n",
    "        print(f\"Patient number: {pat}\")\n",
    "        print(f\"{(((pat+1)/num_pats)*100):.2f}% Complete\")\n",
    "        print(f\"Sensitivity mean +- std: {np.mean(sensitivity_list)}$\\pm${np.std(sensitivity_list)}\")\n",
    "print(f\"Sensitivity mean +- std: {np.mean(sensitivity_list)}$\\pm${np.std(sensitivity_list)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_msk_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
